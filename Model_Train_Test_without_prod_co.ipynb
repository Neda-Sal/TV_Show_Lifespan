{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I will be using the dataset that has the dummy variables for genre and has the ordinal data for MPAA rating. (same as in the third EDA notebook)\n",
    "\n",
    "I will first do a Train-Validate-Test split, and (if I have time) a K-fold cross validation. I will apply these on a linear regression, polynomial, and Ridge regression model. Then I will choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge #ordinary linear regression + w/ ridge regularization\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_pickle('Ordinal_MPAA_merged_with_dummy_genres.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the only columns we care about for our model\n",
    "features = ['Start_Year', 'Num_Episodes_Per_Season', 'Season_1_Rating',\n",
    "            'Action', 'Adventure', 'Animation', 'Biography', 'Comedy', \n",
    "            'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', \n",
    "            'History', 'Horror', 'Music', 'Mystery', 'Other', 'Romance', \n",
    "            'Sci-fi', 'Sport', 'Thriller', 'War', 'Ordinal_MPAA']\n",
    "\n",
    "target = 'Num_of_Seasons'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off the test set\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size = .2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the remaining data into train and validation\n",
    "\n",
    "#keep 25% for validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = .25, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the models I'm going to use\n",
    "\n",
    "- Going to standardize the data for regulariztion\n",
    "- Get some polynomial features for the poly model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 3 models we're choosing from:\n",
    "\n",
    "#basic regression\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_valid_scaled = scaler.transform(X_valid.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "#ridge regression\n",
    "lm_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "#poly regression\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_valid_poly = poly.transform(X_valid.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "lm.fit(X_train, y_train)\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "lm_poly.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic regression R^2 0.4436694565124607\n",
      "Ridge regression R^2 0.4435959744046376\n",
      "Poly regression R^2 -0.27137871508947686\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "print('basic regression R^2', lm.score(X_valid, y_valid))\n",
    "print('Ridge regression R^2', lm_reg.score(X_valid_scaled, y_valid))\n",
    "print('Poly regression R^2', lm_poly.score(X_valid_poly, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like poly regression is overfitting. \n",
    "\n",
    "It also seems like basic regression and Ridge regression have the same R^2. I'll since basic regression score is slightly higher, I will choose to train that one on the entire training+validation set and then check my R^2 with the test set.\n",
    "\n",
    "Further, I can change the seed and rerun the same analyses to double check which might be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2554988765999986"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall that X and y have the train+validate sets already\n",
    "lm.fit(X, y)\n",
    "lm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omg how did it do so poorly now! This probably means my model is very overfit..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a different seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off the test set\n",
    "\n",
    "X2 = df[features]\n",
    "y2 = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X2, X2_test, y2, y2_test = train_test_split(X2, y2, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the remaining data into train and validation\n",
    "\n",
    "#keep 25% for validation\n",
    "X2_train, X2_valid, y2_train, y2_valid = train_test_split(X2, y2, test_size = .25, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 3 models we're choosing from:\n",
    "\n",
    "#basic regression\n",
    "lm2 = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X2_train_scaled = scaler.fit_transform(X2_train.values)\n",
    "X2_valid_scaled = scaler.transform(X2_valid.values)\n",
    "X2_test_scaled = scaler.transform(X2_test.values)\n",
    "\n",
    "#ridge regression\n",
    "lm2_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "#poly regression\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X2_train_poly = poly.fit_transform(X2_train.values)\n",
    "X2_valid_poly = poly.transform(X2_valid.values)\n",
    "X2_test_poly = poly.transform(X2_test.values)\n",
    "\n",
    "lm2_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "lm2.fit(X2_train, y2_train)\n",
    "lm2_reg.fit(X2_train_scaled, y2_train)\n",
    "lm2_poly.fit(X2_train_poly, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4313118596177108"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.score(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic regression R^2 0.35936629845279455\n",
      "Ridge regression R^2 0.3592477942096127\n",
      "Poly regression R^2 0.30989692358312615\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "print('basic regression R^2', lm2.score(X2_valid, y2_valid))\n",
    "print('Ridge regression R^2', lm2_reg.score(X2_valid_scaled, y2_valid))\n",
    "print('Poly regression R^2', lm2_poly.score(X2_valid_poly, y2_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm, the scores went down, and it looks like poly regression might not have overfit this time.. I'll retrain them and then test basic regression and maybe double check the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37283747770196607"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall that X and y have the train+validate sets already\n",
    "lm2.fit(X2, y2)\n",
    "lm2.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wuuuuuuuut... it did better this time! What's with all this variabilty... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37372534404375146"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i\"m just gonna test the other two as well\n",
    "lm2_reg.fit(X2, y2)\n",
    "lm2_reg.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37283747770196607"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2_poly.fit(X2, y2)\n",
    "lm2_poly.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bruh.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try another seed again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off the test set\n",
    "\n",
    "X3 = df[features]\n",
    "y3 = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X3, X3_test, y3, y3_test = train_test_split(X3, y3, test_size = .2, random_state = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the remaining data into train and validation\n",
    "\n",
    "#keep 25% for validation\n",
    "X3_train, X3_valid, y3_train, y3_valid = train_test_split(X3, y3, test_size = .25, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 3 models we're choosing from:\n",
    "\n",
    "#basic regression\n",
    "lm3 = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X3_train_scaled = scaler.fit_transform(X3_train.values)\n",
    "X3_valid_scaled = scaler.transform(X3_valid.values)\n",
    "X3_test_scaled = scaler.transform(X3_test.values)\n",
    "\n",
    "#ridge regression\n",
    "lm3_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "#poly regression\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X3_train_poly = poly.fit_transform(X3_train.values)\n",
    "X3_valid_poly = poly.transform(X3_valid.values)\n",
    "X3_test_poly = poly.transform(X3_test.values)\n",
    "\n",
    "lm3_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "lm3.fit(X3_train, y3_train)\n",
    "lm3_reg.fit(X3_train_scaled, y3_train)\n",
    "lm3_poly.fit(X3_train_poly, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "basic regression R^2 0.44267107708226605\n",
      "Ridge regression R^2 0.4426694010049862\n",
      "Poly regression R^2 0.7934524337290912\n"
     ]
    }
   ],
   "source": [
    "#print training scores\n",
    "print('Training scores')\n",
    "print('basic regression R^2', lm3.score(X3_train, y3_train))\n",
    "print('Ridge regression R^2', lm3_reg.score(X3_train_scaled, y3_train))\n",
    "print('Poly regression R^2', lm3_poly.score(X3_train_poly, y3_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation scores\n",
      "basic regression R^2 0.3067326580191363\n",
      "Ridge regression R^2 0.3080031392282141\n",
      "Poly regression R^2 -4.903849449433565\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "print('validation scores')\n",
    "print('basic regression R^2', lm3.score(X3_valid, y3_valid))\n",
    "print('Ridge regression R^2', lm3_reg.score(X3_valid_scaled, y3_valid))\n",
    "print('Poly regression R^2', lm3_poly.score(X3_valid_poly, y3_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32597428117315497"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm3_reg.fit(X3, y3)\n",
    "lm3_reg.score(X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try cross validation\n",
    "\n",
    "This might be a better esp since I don't have that much data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size = .2, random_state = 10)\n",
    "\n",
    "#this helps with the way kf generates indices\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37168781, 0.35628287, 0.28157213, 0.42676638, 0.39889976])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lm = LinearRegression()\n",
    "\n",
    "cross_val_score(lm, X, y, # estimator, features, target\n",
    "                cv=5, # number of folds \n",
    "                scoring='r2') # scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37215182, 0.28838057, 0.34673255, 0.36824512, 0.48092312])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cross_val_score(lm, X, y, cv=kf, scoring='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## above is the less manual way, gonna try it manually here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = df[features]\n",
    "y4 = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X4, X4_test, y4, y4_test = train_test_split(X4, y4, test_size = .2, random_state = 15)\n",
    "\n",
    "#this helps with the way kf generates indices\n",
    "X4, y4 = np.array(X4), np.array(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple regression scores:  [0.3588733603962003, 0.4094829550457969, 0.32833356931236934, 0.3528023427128436, 0.4024438363057824]\n",
      "Ridge scores:  [0.3590843488292932, 0.4094404773734881, 0.32840463004723275, 0.35332326363708066, 0.402754919272182] \n",
      "\n",
      "Simple mean cv r^2: 0.370 +- 0.031\n",
      "Ridge mean cv r^2: 0.371 +- 0.031\n"
     ]
    }
   ],
   "source": [
    "#run the CV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X4,y4):\n",
    "    \n",
    "    X_train, y_train = X4[train_ind], y4[train_ind]\n",
    "    X_val, y_val = X4[val_ind], y4[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression test R^2: 0.376\n"
     ]
    }
   ],
   "source": [
    "#ridge model did slightly better but it is about the same\n",
    "#let's check on our test set now\n",
    "X_scaled = scaler.fit_transform(X4)\n",
    "X_test_scaled = scaler.transform(X4_test)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_scaled,y4)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y4_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
