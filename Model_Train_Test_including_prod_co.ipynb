{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I will be using the dataset that has all genres as dummy variables, MPAA rating as ordinal data, and a binary column of whether or not a show is produced by a large company. (same as fourth eda notebook)\n",
    "\n",
    "I will first do a Train-Validate-Test split, and (if I have time) a K-fold cross validation. I will apply these on a linear regression, polynomial, and Ridge regression model. Then I will choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge #ordinary linear regression + w/ ridge regularization\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_pickle('all_scraped_features_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the only columns we care about for our model\n",
    "features = ['Start_Year', 'Num_Episodes_Per_Season', 'Season_1_Rating',\n",
    "            'Action', 'Adventure', 'Animation', 'Biography', 'Comedy', \n",
    "            'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', \n",
    "            'History', 'Horror', 'Music', 'Mystery', 'Other', 'Romance', \n",
    "            'Sci-fi', 'Sport', 'Thriller', 'War', 'Ordinal_MPAA', 'Large_prod_co']\n",
    "\n",
    "target = 'Num_of_Seasons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off the test set\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size = .2, random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the remaining data into train and validation\n",
    "\n",
    "#keep 25% for validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = .25, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the models I'm going to use\n",
    "\n",
    "- Going to standardize the data for regulariztion\n",
    "- Get some polynomial features for the poly model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 3 models we're choosing from:\n",
    "\n",
    "#basic regression\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_valid_scaled = scaler.transform(X_valid.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "#ridge regression\n",
    "lm_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "#poly regression\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_valid_poly = poly.transform(X_valid.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "lm.fit(X_train, y_train)\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "lm_poly.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4545373717318719"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic regression R^2 0.44996651176884417\n",
      "Ridge regression R^2 0.4498681789925262\n",
      "Poly regression R^2 -3157222159182.1772\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "print('basic regression R^2', lm.score(X_valid, y_valid))\n",
    "print('Ridge regression R^2', lm_reg.score(X_valid_scaled, y_valid))\n",
    "print('Poly regression R^2', lm_poly.score(X_valid_poly, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like poly reg is HUGELY overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.393544954695196"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall that X and y have the train+validate sets already\n",
    "lm.fit(X, y)\n",
    "lm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split off the test set\n",
    "\n",
    "X2 = df[features]\n",
    "y2 = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X2, X2_test, y2, y2_test = train_test_split(X2, y2, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the remaining data into train and validation\n",
    "\n",
    "#keep 25% for validation\n",
    "X2_train, X2_valid, y2_train, y2_valid = train_test_split(X2, y2, test_size = .25, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 3 models we're choosing from:\n",
    "\n",
    "#basic regression\n",
    "lm2 = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X2_train_scaled = scaler.fit_transform(X2_train.values)\n",
    "X2_valid_scaled = scaler.transform(X2_valid.values)\n",
    "X2_test_scaled = scaler.transform(X2_test.values)\n",
    "\n",
    "#ridge regression\n",
    "lm2_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "#poly regression\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X2_train_poly = poly.fit_transform(X2_train.values)\n",
    "X2_valid_poly = poly.transform(X2_valid.values)\n",
    "X2_test_poly = poly.transform(X2_test.values)\n",
    "\n",
    "lm2_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "lm2.fit(X2_train, y2_train)\n",
    "lm2_reg.fit(X2_train_scaled, y2_train)\n",
    "lm2_poly.fit(X2_train_poly, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4870261773586284"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.score(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic regression R^2 0.3610722944971442\n",
      "Ridge regression R^2 0.361611078703836\n",
      "Poly regression R^2 -17.604024876333213\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "print('basic regression R^2', lm2.score(X2_valid, y2_valid))\n",
    "print('Ridge regression R^2', lm2_reg.score(X2_valid_scaled, y2_valid))\n",
    "print('Poly regression R^2', lm2_poly.score(X2_valid_poly, y2_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3533893218788523"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall that X and y have the train+validate sets already\n",
    "lm2.fit(X2, y2)\n",
    "lm2.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = df[features]\n",
    "y4 = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X4, X4_test, y4, y4_test = train_test_split(X4, y4, test_size = .2, random_state = 15)\n",
    "\n",
    "#this helps with the way kf generates indices\n",
    "X4, y4 = np.array(X4), np.array(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple regression scores:  [0.2545595665407846, -0.07635770722282142, 0.28845148153651246, 0.4477302653702441, 0.3932094730640677]\n",
      "Ridge scores:  [0.25481107035293604, -0.07259972042813767, 0.2889679836390334, 0.4485862745342033, 0.3942733108181389] \n",
      "\n",
      "Simple mean cv r^2: 0.262 +- 0.183\n",
      "Ridge mean cv r^2: 0.263 +- 0.182\n"
     ]
    }
   ],
   "source": [
    "#run the CV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X4,y4):\n",
    "    \n",
    "    X_train, y_train = X4[train_ind], y4[train_ind]\n",
    "    X_val, y_val = X4[val_ind], y4[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression test R^2: 0.404\n"
     ]
    }
   ],
   "source": [
    "#ridge model did slightly better but it is about the same\n",
    "#let's check on our test set now\n",
    "X_scaled = scaler.fit_transform(X4)\n",
    "X_test_scaled = scaler.transform(X4_test)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_scaled,y4)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y4_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a different seed again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = df[features]\n",
    "y5 = df[target]\n",
    "\n",
    "#hold out 20% of the data for final testing\n",
    "\n",
    "X5, X5_test, y5, y_test = train_test_split(X5, y5, test_size = .2, random_state = 36)\n",
    "\n",
    "#this helps with the way kf generates indices\n",
    "X5, y5 = np.array(X5), np.array(y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple regression scores:  [0.30076509342329727, 0.33221047821174454, 0.39201868092635217, 0.27386363303625094, 0.523435511333338]\n",
      "Ridge scores:  [0.30108506487319353, 0.33363221298601153, 0.39307286115622075, 0.27428488241748905, 0.5231784620558233] \n",
      "\n",
      "Simple mean cv r^2: 0.364 +- 0.089\n",
      "Ridge mean cv r^2: 0.365 +- 0.088\n"
     ]
    }
   ],
   "source": [
    "#run the CV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X5,y5):\n",
    "    \n",
    "    X_train, y_train = X5[train_ind], y5[train_ind]\n",
    "    X_val, y_val = X5[val_ind], y5[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression test R^2: 0.359\n"
     ]
    }
   ],
   "source": [
    "#ridge model did slightly better but it is about the same\n",
    "#let's check on our test set now\n",
    "X_scaled = scaler.fit_transform(X5)\n",
    "X_test_scaled = scaler.transform(X5_test)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_scaled,y5)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's a huge variance though. Gonna try Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
